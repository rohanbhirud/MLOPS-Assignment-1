MLOps Assignment â€“ Quick Setup & Deployment Guide (simple, step-by-step)
=======================================================================

Prereqs (install first)
- Python 3.12+, pip
- Docker
- kubectl + Minikube (or Docker Desktop K8s, or a cloud K8s cluster)

1) Get code ready
- Install deps: pip install -r requirements.txt
- Download data: python data/download_data.py --output data/raw/heart.csv
- (Optional) Run tests: pytest -q

2) Train models & generate reports
- Train: python -m src.model_train --data data/raw/heart.csv --models-dir models --reports-dir reports
- Outputs:
  - models/log_reg_pipeline.joblib (pickled best pipeline)
  - reports/metrics.json (CV metrics)
  - reports/figures/* (EDA plots)
  - mlruns/ (MLflow tracking data)

3) Run the API locally (FastAPI)
- Start: uvicorn src.api:app --host 0.0.0.0 --port 8000
- Health: curl http://127.0.0.1:8000/health
- Predict (feature order in src/api.py FEATURE_COLUMNS):
  curl -X POST http://127.0.0.1:8000/predict \
    -H "Content-Type: application/json" \
    -d '{"records":[{"values":[63,1,3,145,233,1,0,150,0,2.3,0,0,1]}]}'
- Metrics (Prometheus format): curl http://127.0.0.1:8000/metrics

4) Build & run with Docker
- docker build -t heart-api .
- docker run -p 8000:8000 heart-api
- Test the same /health, /predict, /metrics endpoints on 127.0.0.1:8000

5) Kubernetes deployment (Minikube example)
- Point docker to Minikube: eval "$(minikube docker-env)"
- Build image in that env: docker build -t heart-api .
- Apply manifests: kubectl apply -f k8s/deployment.yaml
- Check: kubectl get pods; kubectl get svc heart-api
- Port-forward if needed: kubectl port-forward svc/heart-api 8000:8000
- Test endpoints: same curl commands to 127.0.0.1:8000
- Ingress (optional): enable controller (e.g., minikube addons enable ingress), set host heart-api.local, use the Ingress in k8s/deployment.yaml

6) Monitoring & logging
- Logs: kubectl logs -f deploy/heart-api (shows request logs)
- Metrics: curl http://127.0.0.1:8000/metrics (via port-forward) and point Prometheus to scrape that endpoint.
- Grafana: add Prometheus as a data source and chart api_requests_total and api_request_latency_seconds.

7) CI/CD (GitHub Actions)
- Workflow: .github/workflows/ci.yml
- Steps: install deps, download data, run pytest, train models, upload artifacts (models, reports, mlruns).

8) Sharing the bundle
- Zip everything: zip -r mlops_assignment.zip .
- Include key folders: models/, reports/, mlruns/, k8s/, src/, data/, .github/, docs (.md/.txt).

MLflow UI (optional)
- Start UI: mlflow ui --host 127.0.0.1 --port 5001 --backend-store-uri mlruns
- Open: http://127.0.0.1:5001
